# ---------------------------------------------------------------
# This file was automatically generated. DO NOT EDIT MANUALLY.
# 
# Generated by: conor-99/InfiniteARC/prepare.py
# Date: 2025-11-10
# ---------------------------------------------------------------

"""
Task ID: 4211fa7e
Difficulty: insane

=== Tags ===
- Bidirectional escape
- Propagation by rule weight
- Modular sequence
- Recursive agent following
- Count touches

=== Description ===
**Task Description: Bidirectional Escape Cascade**  Input grids feature a
uniform background color (0) overlaid with multiple agents represented by
distinct colors (1–9), each positioned on a grid of interconnected paths. Each
agent has a directional orientation (encoded by its color: 1=↑, 2=↓, 3=→, 4=←,
5=↑↓, 6=→←, 7=↑→, 8=↓←, 9=↑↓→←) and a weight (determined by its color value
modulo 5 + 1). The grid contains walls (color 5) that block movement and modular
path segments (e.g., repeating 3×3 tiles of interconnected cells).   The output
grid transforms the input by applying these rules in sequence:   1.
**Bidirectional escape**: Agents move along paths toward the nearest grid
boundary in their initial direction, reflecting off walls with perfect angle
mirroring (e.g., hitting a vertical wall reverses horizontal direction).
Movement continues until agents exit the grid.   2. **Propagation by rule
weight**: For each step an agent moves, it generates a trail of its color that
spreads radially outward in a pattern dictated by its weight (e.g., weight 3
spreads to cells 3 steps away in all directions). Trails overlap only where
paths intersect.   3. **Modular sequence**: Agents adjust their direction
cyclically every *weight* steps (e.g., weight 2 cycles through ↑→↑→...). This
creates dynamic path deviations based on the agent’s color.   4. **Recursive
agent following**: Each agent follows the path of the *next* agent in the
sequence (agent 1 follows agent 2, agent 2 follows agent 3, ..., agent 9 follows
agent 1), creating a recursive chain where paths are offset by one cell per
step.   5. **Count touches**: Every time an agent’s path intersects a wall,
another agent’s trail, or a boundary, a touch counter increments. When the
counter equals the agent’s weight, the agent’s movement direction resets to its
initial orientation.    The output grid preserves all input elements (agents,
walls, paths) but adds visible trail patterns, directional path deviations, and
recursive path offsets. Trails never overwrite walls or agents, and all
transformations are strictly deterministic based on the input’s color-encoded
properties. The task requires synthesizing all five rules simultaneously to
reconstruct the output from the input.
"""


# ---------------------------------------------------------------
# Generator Code
# ---------------------------------------------------------------

import random
from common import grid

def generate():
    """
    Generate an input/output pair for the Bidirectional Escape Cascade task.
    The generator places a few wall segments (color 5) and several agents (colors 1-9 excluding 5)
    on a zero background. It then deterministically simulates virtual agent movements
    and writes radial trails (never overwriting walls or agents) producing the output.
    The simulation rules mirror the solver implementation so the solver can reconstruct
    the same output from the input alone.
    """
    # Grid size (kept modest to ensure generation is fast)
    width = random.randint(7, 14)
    height = random.randint(7, 14)

    inp = grid(width, height, 0)

    # Place a few random wall segments (color 5), horizontal or vertical
    num_walls = random.randint(3, 5)
    max_seg = max(2, min(width, height) // 2)
    for _ in range(num_walls):
        if random.random() < 0.5:
            # horizontal
            r = random.randint(0, height - 1)
            seg = random.randint(2, max_seg)
            c0 = random.randint(0, max(0, width - seg))
            for c in range(c0, c0 + seg):
                inp[r][c] = 5
        else:
            # vertical
            c = random.randint(0, width - 1)
            seg = random.randint(2, max_seg)
            r0 = random.randint(0, max(0, height - seg))
            for r in range(r0, r0 + seg):
                inp[r][c] = 5

    # Place agents: pick unique colors from 1..9 excluding 5, place on non-wall cells
    possible_colors = [c for c in range(1, 10) if c != 5]
    num_agents = random.randint(3, 5)
    colors = random.sample(possible_colors, num_agents)

    positions = []
    # try to place agents preferably not on the extreme border to increase movement
    tries = 0
    while len(positions) < num_agents and tries < 500:
        r = random.randint(1, height - 2) if height > 2 else random.randint(0, height - 1)
        c = random.randint(1, width - 2) if width > 2 else random.randint(0, width - 1)
        if inp[r][c] == 0 and (r, c) not in positions:
            positions.append((r, c))
        tries += 1
    # fallback to any free cell if couldn't find enough interior spots
    while len(positions) < num_agents:
        r = random.randint(0, height - 1)
        c = random.randint(0, width - 1)
        if inp[r][c] == 0 and (r, c) not in positions:
            positions.append((r, c))

    # Set agent colors into the input grid
    for color, (r, c) in zip(colors, positions):
        inp[r][c] = color

    # Compute output by simulating virtual agents and writing trails
    out = _simulate_trails(inp)

    return {"input": inp, "output": out}


# ------------------ Simulation core (shared logic with solver) ------------------

def _simulate_trails(inp):
    """Simulate virtual agent movement and paint radial trails.
    This function is intentionally self-contained so the solver can replicate it.
    """
    height = len(inp)
    width = len(inp[0])
    # start output as a copy of input (agents and walls preserved)
    out = [row[:] for row in inp]

    # detect agents (cells that are non-zero and not walls)
    agents_found = []  # list of (color, r, c)
    for r in range(height):
        for c in range(width):
            col = inp[r][c]
            if col != 0 and col != 5:
                agents_found.append((col, r, c))
    # deterministic ordering: by color ascending
    agents_found.sort(key=lambda x: x[0])
    n = len(agents_found)
    if n == 0:
        return out

    # directions: 0=up,1=right,2=down,3=left
    dirs = [(-1, 0), (0, 1), (1, 0), (0, -1)]

    # initialize agent state
    agents = []
    for color, r, c in agents_found:
        weight = (color % 5) + 1
        init_dir = (color - 1) % 4
        agents.append({
            "color": color,
            "pos": (r, c),
            "weight": weight,
            "dir": init_dir,
            "init_dir": init_dir,
            "touch": 0,
            "active": True,
            "history": [(r, c)],  # virtual positions over time
            "move_cycle": 0,
        })

    # step cap to ensure termination and fast generation
    step_cap = max(80, (width * height) + 20)

    for step in range(1, step_cap + 1):
        all_inactive = True
        # process agents in deterministic order (sorted by color)
        for i, agent in enumerate(agents):
            if not agent["active"]:
                continue
            all_inactive = False
            r, c = agent["pos"]
            color = agent["color"]
            weight = agent["weight"]

            # try to follow the next agent's previous position (recursive following)
            leader = agents[(i + 1) % n]
            target = None
            # if leader has a history entry for the previous tick, step one cell toward it
            if len(leader["history"]) >= step:
                lr, lc = leader["history"][step - 1]
                dr = lr - r
                dc = lc - c
                if dr != 0 or dc != 0:
                    # move one cell toward the leader (prefer larger delta)
                    if abs(dr) >= abs(dc):
                        step_dr = 1 if dr > 0 else -1
                        step_dc = 0
                    else:
                        step_dr = 0
                        step_dc = 1 if dc > 0 else -1
                    target = (r + step_dr, c + step_dc)

            # fallback to moving in current direction
            if target is None:
                dr, dc = dirs[agent["dir"]]
                target = (r + dr, c + dc)

            tr, tc = target

            # check boundary (exit)
            if not (0 <= tr < height and 0 <= tc < width):
                # hitting the boundary increments touch and causes exit
                agent["touch"] += 1
                agent["active"] = False
                # if touch reached weight, reset direction
                if agent["touch"] >= weight:
                    agent["dir"] = agent["init_dir"]
                    agent["touch"] = 0
                # do not append out-of-bounds history (keeps history length shorter)
                continue

            # if target is a wall, count a touch and reflect (reverse direction), try that move
            if inp[tr][tc] == 5:
                agent["touch"] += 1
                agent["dir"] = (agent["dir"] + 2) % 4
                dr2, dc2 = dirs[agent["dir"]]
                tr2, tc2 = r + dr2, c + dc2
                if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] != 5:
                    tr, tc = tr2, tc2
                else:
                    # couldn't move; stay in place this step (append same pos to keep histories aligned)
                    agent["history"].append((r, c))
                    if agent["touch"] >= weight:
                        agent["dir"] = agent["init_dir"]
                        agent["touch"] = 0
                    continue

            # if target is another agent's original cell (don't step on agents), treat as a touch and try to reflect
            if inp[tr][tc] != 0 and inp[tr][tc] != 5 and (tr, tc) != (r, c):
                agent["touch"] += 1
                agent["dir"] = (agent["dir"] + 2) % 4
                dr2, dc2 = dirs[agent["dir"]]
                tr2, tc2 = r + dr2, c + dc2
                if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] == 0 and inp[tr2][tc2] != 5:
                    tr, tc = tr2, tc2
                else:
                    agent["history"].append((r, c))
                    if agent["touch"] >= weight:
                        agent["dir"] = agent["init_dir"]
                        agent["touch"] = 0
                    continue

            # if target intersects an already-painted trail (out cell non-zero and not wall/agent), it's a touch
            if out[tr][tc] != 0 and out[tr][tc] != 5 and inp[tr][tc] == 0 and (tr, tc) != (r, c):
                agent["touch"] += 1
                agent["dir"] = (agent["dir"] + 2) % 4
                dr2, dc2 = dirs[agent["dir"]]
                tr2, tc2 = r + dr2, c + dc2
                if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] == 0 and out[tr2][tc2] == 0:
                    tr, tc = tr2, tc2
                else:
                    agent["history"].append((r, c))
                    if agent["touch"] >= weight:
                        agent["dir"] = agent["init_dir"]
                        agent["touch"] = 0
                    continue

            # perform the move (virtual)
            agent["pos"] = (tr, tc)
            agent["history"].append((tr, tc))

            # paint a radial (Manhattan) pattern centered on the new virtual position, but never overwrite walls or agents
            for drw in range(-weight, weight + 1):
                rem = weight - abs(drw)
                rr = tr + drw
                if rr < 0 or rr >= height:
                    continue
                cmin = tc - rem
                cmax = tc + rem
                if cmin < 0:
                    cmin = 0
                if cmax >= width:
                    cmax = width - 1
                for cc in range(cmin, cmax + 1):
                    if inp[rr][cc] == 0 and out[rr][cc] == 0:
                        out[rr][cc] = color

            # modular sequence: cycle direction every `weight` successful moves
            agent["move_cycle"] += 1
            if agent["move_cycle"] >= weight:
                agent["dir"] = (agent["dir"] + 1) % 4
                agent["move_cycle"] = 0

            # if touches reached weight reset to initial orientation
            if agent["touch"] >= weight:
                agent["dir"] = agent["init_dir"]
                agent["touch"] = 0

        if all_inactive:
            break

    return out



# ---------------------------------------------------------------
# Solver Code
# ---------------------------------------------------------------

def p(input_grid):
    # Convert input tuple-of-tuples to list-of-lists
    inp = [list(row) for row in input_grid]
    height = len(inp)
    width = len(inp[0]) if height > 0 else 0

    # Reuse the identical simulation used by the generator
    def _simulate_trails_local(inp):
        height = len(inp)
        width = len(inp[0])
        out = [row[:] for row in inp]

        agents_found = []
        for r in range(height):
            for c in range(width):
                col = inp[r][c]
                if col != 0 and col != 5:
                    agents_found.append((col, r, c))
        agents_found.sort(key=lambda x: x[0])
        n = len(agents_found)
        if n == 0:
            return out

        dirs = [(-1, 0), (0, 1), (1, 0), (0, -1)]

        agents = []
        for color, r, c in agents_found:
            weight = (color % 5) + 1
            init_dir = (color - 1) % 4
            agents.append({
                "color": color,
                "pos": (r, c),
                "weight": weight,
                "dir": init_dir,
                "init_dir": init_dir,
                "touch": 0,
                "active": True,
                "history": [(r, c)],
                "move_cycle": 0,
            })

        step_cap = max(80, (width * height) + 20)

        for step in range(1, step_cap + 1):
            all_inactive = True
            for i, agent in enumerate(agents):
                if not agent["active"]:
                    continue
                all_inactive = False
                r, c = agent["pos"]
                color = agent["color"]
                weight = agent["weight"]

                leader = agents[(i + 1) % n]
                target = None
                if len(leader["history"]) >= step:
                    lr, lc = leader["history"][step - 1]
                    dr = lr - r
                    dc = lc - c
                    if dr != 0 or dc != 0:
                        if abs(dr) >= abs(dc):
                            step_dr = 1 if dr > 0 else -1
                            step_dc = 0
                        else:
                            step_dr = 0
                            step_dc = 1 if dc > 0 else -1
                        target = (r + step_dr, c + step_dc)

                if target is None:
                    dr, dc = dirs[agent["dir"]]
                    target = (r + dr, c + dc)

                tr, tc = target

                if not (0 <= tr < height and 0 <= tc < width):
                    agent["touch"] += 1
                    agent["active"] = False
                    if agent["touch"] >= weight:
                        agent["dir"] = agent["init_dir"]
                        agent["touch"] = 0
                    continue

                if inp[tr][tc] == 5:
                    agent["touch"] += 1
                    agent["dir"] = (agent["dir"] + 2) % 4
                    dr2, dc2 = dirs[agent["dir"]]
                    tr2, tc2 = r + dr2, c + dc2
                    if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] != 5:
                        tr, tc = tr2, tc2
                    else:
                        agent["history"].append((r, c))
                        if agent["touch"] >= weight:
                            agent["dir"] = agent["init_dir"]
                            agent["touch"] = 0
                        continue

                if inp[tr][tc] != 0 and inp[tr][tc] != 5 and (tr, tc) != (r, c):
                    agent["touch"] += 1
                    agent["dir"] = (agent["dir"] + 2) % 4
                    dr2, dc2 = dirs[agent["dir"]]
                    tr2, tc2 = r + dr2, c + dc2
                    if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] == 0 and inp[tr2][tc2] != 5:
                        tr, tc = tr2, tc2
                    else:
                        agent["history"].append((r, c))
                        if agent["touch"] >= weight:
                            agent["dir"] = agent["init_dir"]
                            agent["touch"] = 0
                        continue

                if out[tr][tc] != 0 and out[tr][tc] != 5 and inp[tr][tc] == 0 and (tr, tc) != (r, c):
                    agent["touch"] += 1
                    agent["dir"] = (agent["dir"] + 2) % 4
                    dr2, dc2 = dirs[agent["dir"]]
                    tr2, tc2 = r + dr2, c + dc2
                    if 0 <= tr2 < height and 0 <= tc2 < width and inp[tr2][tc2] == 0 and out[tr2][tc2] == 0:
                        tr, tc = tr2, tc2
                    else:
                        agent["history"].append((r, c))
                        if agent["touch"] >= weight:
                            agent["dir"] = agent["init_dir"]
                            agent["touch"] = 0
                        continue

                agent["pos"] = (tr, tc)
                agent["history"].append((tr, tc))

                for drw in range(-weight, weight + 1):
                    rem = weight - abs(drw)
                    rr = tr + drw
                    if rr < 0 or rr >= height:
                        continue
                    cmin = tc - rem
                    cmax = tc + rem
                    if cmin < 0:
                        cmin = 0
                    if cmax >= width:
                        cmax = width - 1
                    for cc in range(cmin, cmax + 1):
                        if inp[rr][cc] == 0 and out[rr][cc] == 0:
                            out[rr][cc] = color

                agent["move_cycle"] += 1
                if agent["move_cycle"] >= weight:
                    agent["dir"] = (agent["dir"] + 1) % 4
                    agent["move_cycle"] = 0

                if agent["touch"] >= weight:
                    agent["dir"] = agent["init_dir"]
                    agent["touch"] = 0

            if all_inactive:
                break

        return out

    return _simulate_trails_local(inp)
